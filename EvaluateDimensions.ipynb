{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating dimensions\n",
    "\n",
    "In this notebook, we test the dimensions for a DeepAnt type neural network. The input parameters are the following:\n",
    "- `n_ts` is the number of variables in the time series. For instance, if the time series is univariate, we will have `n_ts = 1`. For a bivariate time series, we will have `n_ts = 2`, and so on.\n",
    "- `w` is the size of the window we will use as input to the algorithm. If we decide to predict using the past 15 steps, then `w = 15`. \n",
    "- `p_w` is the number of steps in the future we are trying to predict. If we try to predict 3 steps in the future, then `p_w = 3`.\n",
    "- `bs` is the batch size. For the purpose of understanding how dimensions can fit together, we will not consider it since it does not have any impact on dimensions calculations\n",
    "\n",
    "The DeepAnt algorithm is a succession of convolution, activation and pooling layers. Given the shape of the datasets, we have two ways to specify the neural network:\n",
    "\n",
    "- With one-dimension convolutional layers\n",
    "- With two-dimension convolutional layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-dimension convolutional layers\n",
    "\n",
    "If we use one dimension convolutional layers, then the most obvious way to structure the input data is with `n_ts` channels and `w` length, as shown in the picture below.\n",
    "\n",
    "![Image of input dimensions](Images/DeepAnt-OneDimension-Input.png)\n",
    "\n",
    "Let's now define the parameters of the different layers:\n",
    "- Convolution layers:\n",
    "    - `n_fs`: number of filters (for DeepAnt, this will be 32)\n",
    "    - `f_size`: filter size. We'll use filters of size 3 (one dimensional)\n",
    "    - `padding`: padding size in the convolution. We'll use padding of one\n",
    "    - `c_stride`: size of stride. We'll use stride of one (default)\n",
    "- Maximum pooling layers:\n",
    "    - `k_size`: kernel size. We'll use filters of size 3 (one dimensional)\n",
    "    - `padding`: padding size in the maximum pooling. We'll use padding of one\n",
    "    - `p_stride`: size of stride. We'll use stride of 3 (default equal to size of kernel)\n",
    "- Linear (fully connected) layer:\n",
    "    - `p_w`: number of steps to predict in the future\n",
    "    - `n_ts`: number of variable in the time series\n",
    "    \n",
    "The output must be structured with the following dimensions: `n_ts` * `p_w`, as shown below. \n",
    "\n",
    "![Image of output dimensions](Images/DeepAnt-OneDimension-Output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing dimensions in the case of one dimension convolution\n",
    "\n",
    "Let's assume our input has size `n_ts` * `w`. After our first convolution, the size of the output should be the following: `n_c_out` * `c_w_out` where:\n",
    "\n",
    "$$ n\\_c\\_out = n\\_fs $$\n",
    "\n",
    "$$ c\\_w\\_out = \\lfloor\\frac{w + 2 * padding + f\\_size - 2}{c\\_stride} +1\\rfloor $$\n",
    "\n",
    "After our first maximum pooling layer, our dimensions will be `n_fs` * `p_w_out` where:\n",
    "\n",
    "$$ n\\_fs = n\\_fs $$ (unchanged)\n",
    "\n",
    "$$ p\\_w\\_out = \\lfloor\\frac{c\\_w\\_out + 2 * padding + k\\_size - 2}{p\\_stride} + 1\\rfloor $$\n",
    "\n",
    "Let's now define a function that will calculate the dimensions of a CNN with the following strucure:\n",
    "\n",
    "- 1D Convolution\n",
    "- Max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDimensions(window, c_in, n_fs, f_size, padding, c_stride, k_size, p_stride):\n",
    "    n_c_out = n_fs\n",
    "    \n",
    "    c_w_out = floor((window + 2*padding + f_size - 2) / c_stride + 1)\n",
    "    \n",
    "    p_w_out = floor((c_w_out + 2*padding + k_size - 2) / p_stride + 1)\n",
    "    \n",
    "    return (n_fs, p_w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a window of size 25, a quadrivariate time series, convolutions with \n",
    "# 32 kernels (as stated in the DeepAnt paper), convolution filters\n",
    "# of size 3, kernel for max pooling of size 2, convolution stride of 1\n",
    "# pooling stride equel to kernel size (default in pytorch) and \n",
    "# padding of 1\n",
    "\n",
    "window = 25\n",
    "c_in = 4\n",
    "n_fs = 32\n",
    "f_size = 3\n",
    "padding = 1\n",
    "c_stride = 1\n",
    "k_size = 2\n",
    "p_stride = 2\n",
    "\n",
    "(new_c_in, size) = calculateDimensions(window, c_in, n_fs, f_size, padding, c_stride, k_size, p_stride)\n",
    "(new_c_in, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dim1, dim2) = calculateDimensions(size, new_c_in, n_fs, f_size, padding, c_stride, k_size, p_stride)\n",
    "(dim1, dim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the size of the fully connected layer\n",
    "\n",
    "Pytorch `nn.Linear()` class will transform input of size $(N,*,H_{in})$ into $(N,*,H_{out})$, where $N$ is the batch size, $*$ is any number of dimensions that will be **unchanged** and $H_{in}$ and $H_{out}$ are the sizes of the input and output features (see https://pytorch.org/docs/stable/nn.html?highlight=linear#torch.nn.Linear).\n",
    "\n",
    "If we want to output predictions for our time series, this means our output dimensions will be `n_ts` * `p_w` (leaving batch size aside). Therefore, we must first redimension our max pooling output to something that will fit the linear layer. \n",
    "\n",
    "One of the way to do that is to use `Tensor.view()` to redimension one of the dimension to `n_ts`, which means that our input dimensions to the linear layer will be `n_ts` * `redim`, where `redim` will be automatically calculated by the `Tensor.view()` method. However, the tricky part is that the product of the max pool output dimensions **MUST** be divisible by `n_ts`, which will probably not always be the case!!\n",
    "\n",
    "In the previous case, this gives the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = dim1 * dim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c_in is actually n_ts\n",
    "redim = product / c_in\n",
    "redim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's break stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 25\n",
    "c_in = 7\n",
    "n_fs = 32\n",
    "f_size = 3\n",
    "padding = 1\n",
    "c_stride = 1\n",
    "k_size = 2\n",
    "p_stride = 2\n",
    "\n",
    "(new_c_in, size) = calculateDimensions(window, c_in, n_fs, f_size, padding, c_stride, k_size, p_stride)\n",
    "(new_c_in, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dim1, dim2) = calculateDimensions(size, new_c_in, n_fs, f_size, padding, c_stride, k_size, p_stride)\n",
    "(dim1, dim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.857142857142854"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = dim1 * dim2\n",
    "# c_in is actually n_ts\n",
    "redim = product / c_in\n",
    "redim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case above (7 time series) won't work..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-dimension convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
