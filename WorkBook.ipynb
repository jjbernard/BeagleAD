{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WorkBook\n",
    "\n",
    "In this workbook we develop the key components before moving them to Python code. The goal is to interactively develop the code before moving it to pure Python while refactoring it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We need to first load the data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key variables for data loading\n",
    "dirpath = Path('Data')\n",
    "filename = 'data.csv'\n",
    "path = dirpath / filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22695, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp      value\n",
       "0  2013-12-02 21:15:00  73.967322\n",
       "1  2013-12-02 21:20:00  74.935882\n",
       "2  2013-12-02 21:25:00  76.124162\n",
       "3  2013-12-02 21:30:00  78.140707\n",
       "4  2013-12-02 21:35:00  79.329836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of time series in the data is the number of columns minus 1\n",
    "# The first column contains the timestamp\n",
    "nb_ts = data.shape[1] - 1\n",
    "\n",
    "# TOCHECK: what if the data has no timestamp?\n",
    "# TOCHECK: it looks like we don't need this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is the total length of the dataset. We could use len() here\n",
    "N = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has to be manipulated as a numpy array to fit into a torch tensor later\n",
    "data = data.iloc[:,1:].values\n",
    "\n",
    "# TOCHECK: what should we do with the timestamp (when there is one)? Here we drop it, but probably wrong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73.96732207],\n",
       "       [74.935882  ],\n",
       "       [76.12416182],\n",
       "       ...,\n",
       "       [97.13546835],\n",
       "       [98.05685212],\n",
       "       [96.90386085]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define X and y, given that f(X) = y. \n",
    "# The goal of the neural network is the model f()\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call w the size of the window we will use on the time series to predict the output (i.e. the size of X)\n",
    "# Let's call p_w the number of steps in the future we want to predict\n",
    "w = 10\n",
    "p_w = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With w and p_w set, we can now define the number of items that will populate X and y\n",
    "nitems = N + 1 - w - p_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's not populate X and y\n",
    "for i in range(nitems):\n",
    "    X_temp, y_temp = data[i:i+w], data[i+w:i+w+p_w]\n",
    "    X.append(X_temp)\n",
    "    y.append(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nitems == len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split the dataset into training and validation set\n",
    "# We cannot do that randomly, the validation dataset needs to follow the training dataset\n",
    "train_size = 0.8\n",
    "\n",
    "idxvalid = int(nitems * train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's move the data to a torch tensor\n",
    "X, y = torch.Tensor(X).float(), torch.Tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape[0] == nitems\n",
    "assert X.shape[1] == w\n",
    "assert X.shape[2] == nb_ts\n",
    "assert y.shape[0] == nitems\n",
    "assert y.shape[1] == p_w\n",
    "assert y.shape[2] == nb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(X[:idxvalid], y[:idxvalid])\n",
    "valid_ds = TensorDataset(X[idxvalid:], y[idxvalid:])\n",
    "\n",
    "# TOCHECK: should we move to an IterableDataset() instead? See https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the DataLoaders\n",
    "\n",
    "bs = 64\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_dl))\n",
    "\n",
    "# TOCHECK: why is a a list and not a tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some functions\n",
    "\n",
    "def conv(ninputs, nfilters, kernel_size):\n",
    "    return nn.Conv1d(ninputs, nfilters, kernel_size, padding=1, bias=True)\n",
    "\n",
    "def maxpool(filter_size):\n",
    "    return nn.MaxPool1d(filter_size)\n",
    "\n",
    "def activation():\n",
    "    return nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading routine that returns data from a CSV file (initially)\n",
    "\n",
    "def dataloading(path, filename, filetype=\"CSV\"):\n",
    "    \"\"\" Returns a pandas dataframe from a data file\n",
    "        Args:\n",
    "            - path: a Path() object pointing to the directory containing the data\n",
    "            - filename: a file name in CSV format located in the directory pointed \n",
    "            to by the Path() object\n",
    "            - filetype: specify the type of file to read from (at the moment, the\n",
    "            only possibility is \"CSV\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: we should raise exception here if filetype is not CSV\n",
    "    \n",
    "    file = path / filename\n",
    "    if filetype == \"CSV\":\n",
    "        return pd.read_csv(file)\n",
    "    else:\n",
    "        print('Only CSV file are supported at the moment.')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates our dependent and independent variables\n",
    "\n",
    "def createxandy(data, window, p_window, firstcolastime=True):\n",
    "    \"\"\" Returns X and y as torch tensors to be used in our training and predictions\n",
    "        Args:\n",
    "            - data: loaded data in a pandas dataframe format\n",
    "            - window: the length of each X item\n",
    "            - p_window: the length of the prediction window (i.e. how many timesteps in the\n",
    "            future we want to predict)\n",
    "            - firstcolastime: whether our firstcolumn consists of timestamp (default to True)\n",
    "    \"\"\"\n",
    "    \n",
    "    if firstcolastime:\n",
    "        data = data.iloc[:,1:].values\n",
    "    \n",
    "    N = len(data)\n",
    "    \n",
    "    # X will be a list of sequences of size window\n",
    "    # y will be a list of sequences of size p_window, \n",
    "    # immediately following the corresponding X\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Total sequence to go over is N + 1 - window - p_window\n",
    "    seq = N + 1 - window - p_window\n",
    "    for i in range(seq):\n",
    "        X_temp, y_temp = data[i:i+window], data[i+window:i+window+p_window]\n",
    "        X.append(X_temp)\n",
    "        y.append(y_temp)\n",
    "        \n",
    "    X, y = torch.Tensor(X).float(), torch.Tensor(y).float()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's create the datasets we need\n",
    "\n",
    "def createdataset(X, y, split=[0.7,0.3,0.0]):\n",
    "    \"\"\" Returns a list of Dataset objects (for training, validation and testing)\n",
    "        Args:\n",
    "            - X: tensor containing independent variables\n",
    "            - y: tensor containing dependent variables\n",
    "            - split: list containing the split between training, validation \n",
    "            and testing datasets (the total should add to 1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: we should raise exception here\n",
    "    assert sum(split) == 1.0\n",
    "\n",
    "    train_size, valid_size, _ = split\n",
    "    \n",
    "    N = len(X)\n",
    "    \n",
    "    trainidx = int(len(X) * train_size)\n",
    "    valididx = int(len(X) * (train_size + valid_size))\n",
    "    \n",
    "    train_ds = TensorDataset(X[:trainidx], y[:trainidx])\n",
    "    valid_ds = TensorDataset(X[trainidx:valididx], y[trainidx:valididx])\n",
    "    test_ds = TensorDataset(X[valididx:testidx], y[valididx:testidx])\n",
    "    \n",
    "    return [train_ds, valid_ds, test_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the dataloaders\n",
    "\n",
    "def createdataloaders(datasets, bs=64):\n",
    "    \"\"\" Create the dataloaders for all the datasets and returns a list of \n",
    "        dataloaders.\n",
    "        Args:\n",
    "            - datasets: a list of Dataset objects in this order: training, \n",
    "            validation, testing\n",
    "            - bs: batch size (64 by default)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: ensure datasets is of the correct object type\n",
    "    # TOCHECK: should we have shuffle=True or False for validation / testing?\n",
    "    \n",
    "    train_dl = DataLoader(datasets[0], batch_size=bs, shuffle=False)\n",
    "    valid_dl = DataLoader(datasets[1], batch_size=bs, shuffle=True)\n",
    "    test_dl = DataLoader(datasets[2], batch_size=bs, shuffle=True)\n",
    "    \n",
    "    return [train_dl, valid_dl, test_dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
